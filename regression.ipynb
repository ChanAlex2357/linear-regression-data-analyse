{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Numerisation des donnees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation d'un tableau des donees du fichier student-por.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_csv(csv_path:str):\n",
    "    data = pd.read_csv(csv_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodage des donnes\n",
    "\n",
    "- [x]1 school (GP = 1 , MS = 2)\n",
    "- [x]2 sex (F = 1 , M = 2)\n",
    "- [x]4 adress (U = 1 , R = 2) \n",
    "- [x]5 famsize (LE3 = 1 , GT3 = 2)\n",
    "- [x]6 Pstatus (T = 1 , A = 2)\n",
    "- [x]9 Mjob & 10 Fjob (\"teacher\" = 1, \n",
    "                    \"health\" = 2,\n",
    "                    \"services\" = 3,\n",
    "                    \"at_home\" = 4,\n",
    "                    \"other\" = 5)\n",
    "- [x]11 reason (\"home\" = 1,\n",
    "            \"reputation\" = 2,\n",
    "            \"course\" = 3,\n",
    "            \"other\" = 4)\n",
    "- [x]12 guardian (\"mother\" = 1,\n",
    "                \"father\" = 2,\n",
    "                \"other\" = 3)\n",
    "- [x]16 schoolsup (yes=1,no=2)\n",
    "- [x]17 famsup (yes=1,no=2)\n",
    "- [x]18 paid (yes=1,no=2)\n",
    "- [x]19 activities (yes=1,no=2)\n",
    "- [x]20 nursery (yes=1,no=2)\n",
    "- [x]21 higher (yes=1,no=2)\n",
    "- [x]22 internet (yes=1,no=2)\n",
    "- [x]23 romantic (yes=1,no=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction d'encodage de donnee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Permet de faire l'encodage des donnees \n",
    "    ARGS\n",
    "        - data : la liste des donnees\n",
    "        - indexes : la listes des colonnes a encoder\n",
    "        - encode_rules : un dictionaire des regles a suivre pour encodes la valeur des donnees\n",
    "'''\n",
    "def encodage(data,indexes:list,encode_rules):\n",
    "    for i in range(len(data)):\n",
    "        for index in indexes:\n",
    "            value = data.loc[i,index]\n",
    "            try:\n",
    "                value = encode_rules[index][value]\n",
    "            except :\n",
    "                value = encode_rules[value]\n",
    "            data.loc[i,index] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodage(data=students,\n",
    "#          indexes=[\"school\",\n",
    "#                   \"sex\",\n",
    "#                   \"address\",\n",
    "#                   \"famsize\",\n",
    "#                   \"Pstatus\",\n",
    "#                   \"Mjob\",\n",
    "#                   \"Fjob\",\n",
    "#                   \"reason\",\n",
    "#                   \"guardian\",\n",
    "#                   \"schoolsup\",\n",
    "#                   \"famsup\",\n",
    "#                   \"paid\",\n",
    "#                   \"activities\",\n",
    "#                   \"nursery\",\n",
    "#                   \"higher\",\n",
    "#                   \"internet\",\n",
    "#                   \"romantic\"\n",
    "#                 ],\n",
    "#          encode_rules={ 'GP':0 , 'MS':1,# school\n",
    "#                         'F':0 , 'M':1,  # sex\n",
    "#                         'U':0 , 'R':1,   # address\n",
    "#                         'LE3':0 ,'GT3':1, # famsize\n",
    "#                         'T':0 , 'A':1,  # Pstatus\n",
    "#                         'teacher':0,'health':1,'services':2,'at_home':3,\n",
    "#                         'Mjob':{'other':4}, # Mjob\n",
    "#                         'Fjob':{'other':4}, # Fjob\n",
    "#                         \"home\":0,\"reputation\":1,\"course\":2,\n",
    "#                         \"reason\":{\"other\":3},   #reason\n",
    "#                         \"guardian\": {\"mother\":0,\"father\":1,\"other\":2},  # guardian\n",
    "#                         'yes':0,'no':1 \n",
    "#                     }\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Coefficient de correlation\n",
    "\n",
    "\n",
    "r = sum((xi - x)(yi - y)) / sqrt( sum((xi - x)^2) * sum((yi - y)^2) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Cree un tableau des coefficient de correlations entre 2 ligne de donnee '''\n",
    "def cor_coeff(data,index_x,index_y):\n",
    "    coffs = None\n",
    "    # Recuperation des donnees des colonnes\n",
    "    x_values = data[index_x]\n",
    "    y_values = data[index_y]\n",
    "    # Calculer la moyenne x_bar\n",
    "    x_bar = np.mean(x_values)\n",
    "    # Calculer la moyenne y_bar\n",
    "    y_bar = np.mean(y_values)\n",
    "\n",
    "    numerateur = 0\n",
    "    d_sum1 = 0\n",
    "    d_sum2 = 0\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        calc_x = x_values[i] - x_bar # xi - x\n",
    "        calc_y = y_values[i] - y_bar # yi - y\n",
    "\n",
    "        numerateur += (calc_x*calc_y)\n",
    "        d_sum1 += (calc_x)**2\n",
    "        d_sum2 += (calc_y)**2\n",
    "\n",
    "    return numerateur / np.sqrt((d_sum1)*(d_sum2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calcul les coefficients de corelations pour tous les collumns du data '''\n",
    "def cors_coeffs(data):\n",
    "    indexes = data.columns\n",
    "    corr = dict()\n",
    "    for x_index in indexes:\n",
    "        value = dict()\n",
    "        for y_index in indexes:\n",
    "            value.__setitem__(y_index,cor_coeff(data,x_index,y_index))\n",
    "        corr.__setitem__(x_index,value)\n",
    "    return pd.DataFrame(corr) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyser les coefficients de corelation pour decider des colonnes a garder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Regression lineaire\n",
    "\n",
    "Le but est de trouver une relation explicative entre une colonne Y et le reste des variales X\n",
    "\n",
    "## Modelisation du probleme\n",
    "\n",
    "Tena tanjona mahazo droite anakiray otriotrinzao :\n",
    "$${\n",
    "    y_i = a_0 + a_1 X_{i,1} + a_2 X_{i,2} + . . . + a_p X_{i,p} + ε_i ,\\space\\space\n",
    "i = 1, . . . , n\n",
    "}$$\n",
    "Fa probleme anzay droite anakiray tokony mampety ny ligne de donees rehetra zay mety misy erreur\n",
    "\n",
    "Supposons hananana valeur a0,...,ap donc hananana le droite\n",
    "\n",
    "Rah tsy hanana le droite de inona tanjona?\n",
    "Ahoana ny isafidianana anle droite tsara , minimiser le plus possible les erreurs soit faire en sorte que la somme des erreurs soit egale a 0 en choisissant les estimateurs b = a_chapeau\n",
    "$${\n",
    "    t_i = b_0 + b_1 X_{i,1} + b_2 X_{i,2} + . . . + b_p X_{i,p} + ε_i ,\\space\\space\n",
    "i = 1, . . . , n\n",
    "}$$\n",
    "\n",
    "enfaite l'erreur peut etre formaliser comme tel :\n",
    "\n",
    "$${ ε_i ≡ y_i − ŷ_i }$$\n",
    "\n",
    "et donc minimiser cette erreur revient a faire son optimisation\n",
    "\n",
    "Apres certaines demonstration on arrive a :\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des estimateurs de moindre carre\n",
    "\n",
    "$${A = (X^TX)^{-1}  X^TY}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Determiner les coefficients de la droite de regression \n",
    "entre des donnees explicatifs et des donnees a expliquer avec\n",
    "A = inv(Xt.X).Xt.Y\n",
    "    ARGS \n",
    "        X : les valeurs explicatifs\n",
    "        Y : les valeurs a expliques\n",
    "    RETURN\n",
    "        A les coefficients de la droite de regression\n",
    "'''\n",
    "def get_coeff_lineaire(x:pd.DataFrame,y:pd.DataFrame):\n",
    "    # Calcul de la transposer de x\n",
    "    xt = np.transpose(x)\n",
    "    # Calcul de Xt.X\n",
    "    xt_x = xt.dot(x)\n",
    "    # Calcul de inv(Xt.X)\n",
    "    xt_x = xt_x.astype(float)\n",
    "    inv = np.linalg.inv(xt_x.values)\n",
    "    inverse = pd.DataFrame(inv,xt_x.columns,xt_x.index)\n",
    "    # Calcul de Xt.Y\n",
    "    xt_y = xt.dot(y)\n",
    "    # Calucul inv(Xt.X).Xt.Y\n",
    "    a = inverse.dot(xt_y)\n",
    "    return a\n",
    "\n",
    "''' Determiner les coefficients de la droite de regresseion pour une colonne a expliquer specifier \n",
    "    ARGS    \n",
    "        data\n",
    "'''\n",
    "def reg_model(data:pd.DataFrame , index):\n",
    "    X = data.drop(index, axis='columns')\n",
    "    # Création d'une colonne de 1s\n",
    "    colonne_de_1s = np.ones((X.shape[0],1))\n",
    "    # Ajout de la colonne de 1s à la matrice X\n",
    "    X = pd.DataFrame(np.hstack((colonne_de_1s, X)))\n",
    "    Y = pd.DataFrame(data[index])\n",
    "    model= get_coeff_lineaire(X,Y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul du coefficient de determination\n",
    "\n",
    "- [x] calcul de  scr\n",
    "    - scr = sum (yi - yi_ )^2\n",
    "- [x] calcul de sce\n",
    "    - sce = sum((yi)^2 - y_bar)\n",
    "- [x] calcul de sct = sce + scr\n",
    "- [x] calcul de r2 = sce/sct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Permet de faire l'estimation ou prediction d'une colonne avec un model de regression '''\n",
    "def get_estimation_lineaire(data:pd.DataFrame,index,model):\n",
    "    estimations = list()\n",
    "    # Les coefficents estimateur pour la doite \n",
    "    coeffs = model\n",
    "    X = data.drop(index, axis='columns')\n",
    "    for i in range(len(data)):\n",
    "        yi = coeffs[index][0]\n",
    "        j = 1\n",
    "        for j_index in X.columns:\n",
    "            xij =  data[j_index][i]\n",
    "            yi += coeffs[index][j]*xij\n",
    "            j+=1\n",
    "        estimations.append(yi)\n",
    "    \n",
    "    return pd.DataFrame({index:estimations})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Determine le coefficient de determination pour connaitre la force du pouvoir predictif du model'''\n",
    "def det_coeff(data:pd.DataFrame,index,model):\n",
    "    Y = pd.DataFrame(data[index])\n",
    "    # Creation de la matrice y des valeurs estimees\n",
    "    y = get_estimation_lineaire(data,index,model)\n",
    "    # Calcul des sommes\n",
    "    scr = 0\n",
    "    sce = 0\n",
    "    y_bar = np.mean(Y.values)\n",
    "    for i in range(len(data)):\n",
    "        # Calcul de scr\n",
    "        scr += (Y[index][i] - y[index][i])**2\n",
    "        # Calcul de sce\n",
    "        sce += ((y[index][i])**2 - y_bar)\n",
    "    sct = scr + sce\n",
    "    \n",
    "    r2 = sce/sct\n",
    "    return r2\n",
    "# det_coeff(students,\"G3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Test\n",
    "\n",
    "Cree une fonction qui teste la variance des erreurs des donnees\n",
    "\n",
    "f(data , pourcentage , cible)\n",
    "\n",
    "- [x] separer les donnee\n",
    "    - [x] shuffle le data\n",
    "    - [x] utiliser les  pourcentage data pour le coeff de determination\n",
    "    - [x] utiliser le reste pour determiner les coefficients de corelations\n",
    "- [x] toruver les coeffs de corelation\n",
    "- [x] eliminer les colonnes qui sont pas tres en corelation\n",
    "- [x] trouver le coeff de deterination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Analyse le tableau des coefficients de corelation et determine a partir de cor_min les variables a \n",
    "    garder pour un index specifier\n",
    "    ARGS\n",
    "        data : la liste des donnees\n",
    "        cor_coeffs : les coefficients de corelations\n",
    "        index : le nom du colonne / variable de reference\n",
    "        cor_min : le barem a suivre >=(+/-)corcor_min\n",
    "    RETURN\n",
    "        un tableau des donnees avec uniquement les variables colineaires entre-elles\n",
    "'''\n",
    "def cor_indexes( data:pd.DataFrame , cor_coeffs:pd.DataFrame , index:str , cor_min:float):\n",
    "    # Recuperation des coefficients pour l'Index\n",
    "    coeffs = cor_coeffs[index]\n",
    "    # Cree une variable d'iteration des resultats\n",
    "    result = data\n",
    "    # Pour tout les indexes possibles on compare sa coefficent de corelastion\n",
    "    # coeff <cor_min < \n",
    "    for variable in data.columns:\n",
    "        coeff = cor_coeffs[index][variable]\n",
    "        if ((coeff > -cor_min) and (coeff < cor_min) ):\n",
    "            result = result.drop(variable,axis='columns')\n",
    "    return result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sum_error(data:pd.DataFrame , index:str , model):\n",
    "    Y = pd.DataFrame(data[index])\n",
    "    y = get_estimation_lineaire(data,index,model)\n",
    "\n",
    "    result = 0\n",
    "    for i in range(len(data)):\n",
    "        result += (Y[index][i] - y[index][i])**2\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "tab = []\n",
    "tab.append(5)\n",
    "print ((tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    school sex  age address famsize Pstatus  Medu  Fedu Mjob Fjob  ... famrel  \\\n",
      "0        0   1   15       0       0       1     2     1    2    4  ...      4   \n",
      "1        0   1   18       0       0       0     1     1    4    4  ...      2   \n",
      "2        0   1   16       0       0       0     2     1    3    4  ...      4   \n",
      "3        0   0   15       1       1       0     3     3    2    2  ...      4   \n",
      "4        0   1   19       0       1       0     3     2    2    3  ...      4   \n",
      "..     ...  ..  ...     ...     ...     ...   ...   ...  ...  ...  ...    ...   \n",
      "157      0   1   18       0       1       0     4     4    0    2  ...      3   \n",
      "158      0   0   18       0       1       0     4     4    1    1  ...      2   \n",
      "159      0   0   17       0       1       0     2     2    4    2  ...      4   \n",
      "160      0   0   19       1       1       0     3     2    2    2  ...      3   \n",
      "161      0   1   18       0       0       0     4     3    0    2  ...      4   \n",
      "\n",
      "    freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
      "0          5      5     2     5      5        0  12  11  11  \n",
      "1          3      5     2     5      4        0  11   9   0  \n",
      "2          4      4     3     5      5        6   9  10  10  \n",
      "3          2      1     2     3      3        2  13  13  13  \n",
      "4          5      4     1     1      4        6  11   9  11  \n",
      "..       ...    ...   ...   ...    ...      ...  ..  ..  ..  \n",
      "157        2      4     1     4      3        6  11  12  12  \n",
      "158        4      4     1     1      4        2  14  12  13  \n",
      "159        2      3     1     1      1        8  13  15  15  \n",
      "160        3      3     4     3      3        0   9   8  10  \n",
      "161        2      3     1     2      1        0  10  10  10  \n",
      "\n",
      "[162 rows x 33 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n       'Walc', 'health', 'absences', 'G1', 'G2', 'G3'],\n      dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Work Section\\INFORMATIQUE\\BINARY\\S4\\Analyse de donnees\\linear-regression-data-analyse\\regression.ipynb Cell 23\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m students \u001b[39m=\u001b[39m load_data_from_csv(\u001b[39m\"\u001b[39m\u001b[39m3_donnees_student/student-por.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m encodage(data\u001b[39m=\u001b[39mstudents,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m          indexes\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mschool\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39msex\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m                     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m         )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m test(students,\u001b[39m0.25\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mG3\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32me:\\Work Section\\INFORMATIQUE\\BINARY\\S4\\Analyse de donnees\\linear-regression-data-analyse\\regression.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     d1 \u001b[39m=\u001b[39m (shuffled_data\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m:depart])\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     d2 \u001b[39m=\u001b[39m (shuffled_data\u001b[39m.\u001b[39miloc[arrivee:n_data])\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     coeff_data \u001b[39m=\u001b[39m d1\u001b[39m.\u001b[39;49mjoin(d2)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m ~ \u001b[39m\u001b[39m{\u001b[39;00mdepart\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00marrivee\u001b[39m}\u001b[39;00m\u001b[39m ~\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m,d1,d2,coeff_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# # Determiner les coefficients de corelation selon les donees selectionnees\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# corelation_coeffs = cors_coeffs(coeff_data)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# # Garder que les colonnes en corelation avec la cibl\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39m# arrivee = depart + nombre_lignes_x\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Work%20Section/INFORMATIQUE/BINARY/S4/Analyse%20de%20donnees/linear-regression-data-analyse/regression.ipynb#X30sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39m# tested += nombre_lignes_x\u001b[39;00m\n",
      "File \u001b[1;32me:\\Softwares\\Python\\Py V3.11\\Lib\\site-packages\\pandas\\core\\frame.py:10744\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[0;32m  10734\u001b[0m     \u001b[39mif\u001b[39;00m how \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcross\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m  10735\u001b[0m         \u001b[39mreturn\u001b[39;00m merge(\n\u001b[0;32m  10736\u001b[0m             \u001b[39mself\u001b[39m,\n\u001b[0;32m  10737\u001b[0m             other,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10742\u001b[0m             validate\u001b[39m=\u001b[39mvalidate,\n\u001b[0;32m  10743\u001b[0m         )\n\u001b[1;32m> 10744\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[0;32m  10745\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m  10746\u001b[0m         other,\n\u001b[0;32m  10747\u001b[0m         left_on\u001b[39m=\u001b[39;49mon,\n\u001b[0;32m  10748\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[0;32m  10749\u001b[0m         left_index\u001b[39m=\u001b[39;49mon \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m  10750\u001b[0m         right_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m  10751\u001b[0m         suffixes\u001b[39m=\u001b[39;49m(lsuffix, rsuffix),\n\u001b[0;32m  10752\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m  10753\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[0;32m  10754\u001b[0m     )\n\u001b[0;32m  10755\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m  10756\u001b[0m     \u001b[39mif\u001b[39;00m on \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32me:\\Softwares\\Python\\Py V3.11\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result(copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32me:\\Softwares\\Python\\Py V3.11\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:888\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[0;32m    886\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 888\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_and_concat(\n\u001b[0;32m    889\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39;49mcopy\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    891\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n\u001b[0;32m    893\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n",
      "File \u001b[1;32me:\\Softwares\\Python\\Py V3.11\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:840\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    837\u001b[0m left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft[:]\n\u001b[0;32m    838\u001b[0m right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright[:]\n\u001b[1;32m--> 840\u001b[0m llabels, rlabels \u001b[39m=\u001b[39m _items_overlap_with_suffix(\n\u001b[0;32m    841\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuffixes\n\u001b[0;32m    842\u001b[0m )\n\u001b[0;32m    844\u001b[0m \u001b[39mif\u001b[39;00m left_indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[39mlen\u001b[39m(left)):\n\u001b[0;32m    845\u001b[0m     \u001b[39m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[0;32m    846\u001b[0m     \u001b[39m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[0;32m    847\u001b[0m     \u001b[39m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[0;32m    848\u001b[0m     lmgr \u001b[39m=\u001b[39m left\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mreindex_indexer(\n\u001b[0;32m    849\u001b[0m         join_index,\n\u001b[0;32m    850\u001b[0m         left_indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    855\u001b[0m         use_na_proxy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    856\u001b[0m     )\n",
      "File \u001b[1;32me:\\Softwares\\Python\\Py V3.11\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2721\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[1;34m(left, right, suffixes)\u001b[0m\n\u001b[0;32m   2718\u001b[0m lsuffix, rsuffix \u001b[39m=\u001b[39m suffixes\n\u001b[0;32m   2720\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m lsuffix \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m rsuffix:\n\u001b[1;32m-> 2721\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcolumns overlap but no suffix specified: \u001b[39m\u001b[39m{\u001b[39;00mto_rename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2723\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrenamer\u001b[39m(x, suffix: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2724\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2725\u001b[0m \u001b[39m    Rename the left and right indices.\u001b[39;00m\n\u001b[0;32m   2726\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2737\u001b[0m \u001b[39m    x : renamed column name\u001b[39;00m\n\u001b[0;32m   2738\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n       'Walc', 'health', 'absences', 'G1', 'G2', 'G3'],\n      dtype='object')"
     ]
    }
   ],
   "source": [
    "'''Fonction de test la qualite de la regression'''\n",
    "def test(data:pd.DataFrame , pourcentage:float , cible:str ):\n",
    "    # Separation des donnees\n",
    "    shuffled_data   = data\n",
    "    # Calcul du nombre de lignes à conserver pour l'échantillon\n",
    "    nombre_lignes_x = int(len(shuffled_data) * pourcentage)\n",
    "    n_data = len(shuffled_data)\n",
    "    depart = 162\n",
    "    arrivee = 324\n",
    "    tested = 0\n",
    "    residus = []\n",
    "    # while ( tested < n_data):\n",
    "    # Sélection des premières lignes pour former l'échantillon\n",
    "    test_data = shuffled_data.iloc[depart:arrivee].reset_index(drop=True)\n",
    "    print(test_data)\n",
    "    # Le reste des lignes forme l'échantillon de test\n",
    "    if depart == 0 :\n",
    "        coeff_data = (shuffled_data.iloc[arrivee:n_data]).reset_index(drop=True)\n",
    "    elif arrivee == n_data:\n",
    "        coeff_data = (shuffled_data.iloc[0:depart]).reset_index(drop=True)\n",
    "    else :\n",
    "        d1 = (shuffled_data.iloc[0:depart]).reset_index(drop=True)\n",
    "        d2 = (shuffled_data.iloc[arrivee:n_data]).reset_index(drop=True)\n",
    "        coeff_data = d1.join(d2)\n",
    "    print(f\" ~ {depart} {arrivee} ~\\n \",d1,d2,coeff_data)\n",
    "    # # Determiner les coefficients de corelation selon les donees selectionnees\n",
    "    # corelation_coeffs = cors_coeffs(coeff_data)\n",
    "    # # Garder que les colonnes en corelation avec la cibl\n",
    "    # test_data = cor_indexes(data=test_data,\n",
    "    #                         cor_coeffs=corelation_coeffs,\n",
    "    #                         index=cible,\n",
    "    #                         cor_min=0.1)\n",
    "    # model = reg_model(test_data,cible)\n",
    "    # residu_sum = data_sum_error(test_data,cible,model)\n",
    "    # residus.append(residu_sum)\n",
    "        \n",
    "        # depart = arrivee\n",
    "        # arrivee = depart + nombre_lignes_x\n",
    "        # tested += nombre_lignes_x\n",
    "    return residus\n",
    "\n",
    "\n",
    "students = load_data_from_csv(\"3_donnees_student/student-por.csv\")\n",
    "encodage(data=students,\n",
    "         indexes=[\"school\",\n",
    "                  \"sex\",\n",
    "                  \"address\",\n",
    "                  \"famsize\",\n",
    "                  \"Pstatus\",\n",
    "                  \"Mjob\",\n",
    "                  \"Fjob\",\n",
    "                  \"reason\",\n",
    "                  \"guardian\",\n",
    "                  \"schoolsup\",\n",
    "                  \"famsup\",\n",
    "                  \"paid\",\n",
    "                  \"activities\",\n",
    "                  \"nursery\",\n",
    "                  \"higher\",\n",
    "                  \"internet\",\n",
    "                  \"romantic\"\n",
    "                ],\n",
    "         encode_rules={ 'GP':0 , 'MS':1,# school\n",
    "                        'F':0 , 'M':1,  # sex\n",
    "                        'U':0 , 'R':1,   # address\n",
    "                        'LE3':0 ,'GT3':1, # famsize\n",
    "                        'T':0 , 'A':1,  # Pstatus\n",
    "                        'teacher':0,'health':1,'services':2,'at_home':3,\n",
    "                        'Mjob':{'other':4}, # Mjob\n",
    "                        'Fjob':{'other':4}, # Fjob\n",
    "                        \"home\":0,\"reputation\":1,\"course\":2,\n",
    "                        \"reason\":{\"other\":3},   #reason\n",
    "                        \"guardian\": {\"mother\":0,\"father\":1,\"other\":2},  # guardian\n",
    "                        'yes':0,'no':1 \n",
    "                    }\n",
    "        )\n",
    "test(students,0.25,\"G3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
